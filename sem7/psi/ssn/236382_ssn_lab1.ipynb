{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Ćwiczenie 1\n",
    "## # Sprawozdanie: Klasyfikacja za pomocą pojedynczego neuronu uczonego metodą bezgradientową"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Cel ćwiczenia\n",
    "Celem zadania było zaprojektowanie modelu neuronu (bazującego na modelu McCullochaPittsa) z dwoma wejściami, który potrafi klasyfikować punkty należące do dwóch liniowo\n",
    "separowalnych zbiorów. Po zakończeniu procesu uczenia sprawdzono, z jaką skutecznością neuron\n",
    "poprawnie klasyfikuje dostarczone punkty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Wstęp teoretyczny\n",
    "Pojedynczy neuron stanowi podstawowy element sieci neuronowych, a jego działanie opiera się na matematycznym modelu zaproponowanym przez McCullocha i Pittsa. Model ten opisuje neuron jako funkcję przyjmującą zestaw wejść, które są ważone i sumowane, a następnie przepuszczane przez funkcję aktywacji.\n",
    "\n",
    "W tym ćwiczeniu zastosowano funkcję Heaviside’a, która określa próg aktywacji.\n",
    "\n",
    "$$\n",
    "f(x) =\n",
    "\\begin{cases}\n",
    "1, & \\text{dla } x > 0 \\\\\n",
    "0, & \\text{dla } x \\leq 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "Neuron może być wykorzystany do klasyfikacji punktów w przestrzeni dwuwymiarowej, o ile są one liniowo separowalne. Klasyfikacja ta polega na znalezieniu odpowiednich wag \\( w_1, w_2 \\) oraz przesunięcia \\( b \\), które definiują prostą decyzyjną:\n",
    "\n",
    "$$\n",
    "    y = f(w_1 \\cdot x_1 + w_2 \\cdot x_2 + b)\n",
    "$$\n",
    "\n",
    "Uczenie metodą bezgradientową polega na iteracyjnej korekcie wag i przesunięcia w taki sposób, aby dla każdego punktu błędy klasyfikacji były eliminowane. Proces ten kontynuowany jest aż do momentu uzyskania poprawnej klasyfikacji całego zbioru uczącego."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Implementacja w języku Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T04:50:33.186338200Z",
     "start_time": "2025-03-01T04:50:33.137269400Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "## 1. Definicja funkcji aktywacji\n",
    "\n",
    "### Rola funkcji aktywacji - Heaviside’a\n",
    "Funkcja decyduje o tym, czy neuron zostanie aktywowany (czyli czy zwróci wartość 1) lub pozostanie nieaktywny (zwróci 0). W kontekście perceptronu funkcja ta odpowiada za podział przestrzeni wejściowej na dwie klasy, co pozwala na liniową separację zbioru danych. Wartość wyjściowa neuronu zależy od sumy ważonej wejść i przesunięcia (biasu). Jeśli suma ta przekracza 0, neuron aktywuje się, w przeciwnym razie pozostaje nieaktywny.\n",
    "\n",
    "Dzięki takiemu podejściu perceptron może klasyfikować punkty na podstawie prostej decyzyjnej. Jest to szczególnie przydatne w problemach, w których klasy można oddzielić za pomocą jednej linii."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Funkcja Heaviside'a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T04:50:33.187338100Z",
     "start_time": "2025-03-01T04:50:33.146128200Z"
    }
   },
   "outputs": [],
   "source": [
    "def heaviside(x):\n",
    "    return np.where(x > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2. Implementacja perceptronu\n",
    "Perceptron przechowuje wagi, bias oraz umożliwia uczenie się na podstawie dostarczonych danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T04:50:33.236068200Z",
     "start_time": "2025-03-01T04:50:33.156653700Z"
    }
   },
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, learning_rate=0.1, n_iter=10):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Inicjalizacja wag (pierwszy element to bias)\n",
    "        self.weights = np.zeros(1 + X.shape[1])\n",
    "\n",
    "        # Pętla po iteracjach\n",
    "        for _ in range(self.n_iter):\n",
    "            for xi, target in zip(X, y):\n",
    "                # Obliczenie różnicy między wartością oczekiwaną a przewidywaną\n",
    "                update = self.learning_rate * (target - self.predict_single(xi))\n",
    "                # Aktualizacja wag (wraz z biasem)\n",
    "                self.weights[1:] += update * xi\n",
    "                self.weights[0] += update\n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        # Obliczenie sumy ważonej (wraz z biasem)\n",
    "        return np.dot(X, self.weights[1:]) + self.weights[0]\n",
    "\n",
    "    def predict_single(self, x):\n",
    "        # Funkcja aktywacji: zwraca 1, jeśli net_input >= 0, w przeciwnym razie 0\n",
    "        return np.where(self.net_input(x) >= 0.0, 1, 0)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Predykcja dla wielu punktów\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Dane treningowe\n",
    "\n",
    "Tworzymy zbiór punktów, które są liniowo separowalne. Każdy punkt jest oznaczony jako należący do jednej z dwóch klas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T04:50:33.238069200Z",
     "start_time": "2025-03-01T04:50:33.163231Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)  # Ustalenie ziarna dla powtarzalności wyników\n",
    "\n",
    "# Tworzymy dwa zbiory punktów:\n",
    "# Klasa 0: punkty skupione wokół (-1, -1)\n",
    "X0 = np.random.randn(50, 2) - [1, 1]\n",
    "# Klasa 1: punkty skupione wokół (1, 1)\n",
    "X1 = np.random.randn(50, 2) + [1, 1]\n",
    "\n",
    "# Łączymy dane treningowe\n",
    "X_train = np.vstack((X0, X1))\n",
    "y_train = np.array([0] * 50 + [1] * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4. Trenowanie perceptronu\n",
    "Tworzymy instancję perceptronu i trenujemy go na wcześniej przygotowanych danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T04:50:33.239069300Z",
     "start_time": "2025-03-01T04:50:33.172302600Z"
    }
   },
   "outputs": [],
   "source": [
    "perceptron = Perceptron(learning_rate=0.1, n_iter=10)\n",
    "perceptron.fit(X_train, y_train)\n",
    "\n",
    "# Predykcje dla danych treningowych (opcjonalnie można sprawdzić, czy klasyfikacja jest poprawna)\n",
    "train_predictions = perceptron.predict(X_train)\n",
    "print(\"Predykcje na zbiorze treningowym:\", train_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 5. Testowanie perceptronu\n",
    "Po zakończeniu procesu uczenia sprawdzamy działanie perceptronu na nowych punktach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T04:50:33.239069300Z",
     "start_time": "2025-03-01T04:50:33.199914500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Definiujemy kilka punktów testowych\n",
    "new_points = np.array([\n",
    "    [-2, -2],\n",
    "    [2, 2],\n",
    "    [0, 0],\n",
    "    [-1.5, -0.5],\n",
    "    [1.5, 0.5]\n",
    "])\n",
    "\n",
    "test_predictions = perceptron.predict(new_points)\n",
    "print(\"Predykcje dla nowych punktów:\", test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 6. Wizualizacja wyników\n",
    "Przedstawiamy wyniki klasyfikacji oraz granicę decyzyjną perceptronu na wykresie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T04:50:33.239069300Z",
     "start_time": "2025-03-01T04:50:33.207433600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ustalamy zakres wykresu\n",
    "x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
    "                     np.arange(y_min, y_max, 0.02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T04:50:33.523913400Z",
     "start_time": "2025-03-01T04:50:33.220537400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predykcje dla każdego punktu siatki, aby narysować granicę decyzyjną\n",
    "Z = perceptron.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.contourf(xx, yy, Z, alpha=0.4, cmap=plt.cm.Paired)\n",
    "plt.scatter(X0[:, 0], X0[:, 1], color='red', marker='o', label='Klasa 0 (trening)')\n",
    "plt.scatter(X1[:, 0], X1[:, 1], color='blue', marker='x', label='Klasa 1 (trening)')\n",
    "plt.scatter(new_points[:, 0], new_points[:, 1], color='green', marker='s', label='Punkty testowe')\n",
    "plt.xlabel('Cecha 1')\n",
    "plt.ylabel('Cecha 2')\n",
    "plt.title('Granica decyzyjna perceptronu')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-01T04:54:07.913778900Z",
     "start_time": "2025-03-01T04:54:07.892611400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Zakładane etykiety dla punktów testowych (ground truth)\n",
    "expected_labels = np.array([0, 1, 1, 0, 1])\n",
    "\n",
    "# Obliczenie skuteczności predykcji\n",
    "accuracy = np.mean(test_predictions == expected_labels)\n",
    "print(\"Skuteczność predykcji punktów testowych: {:.2f}%\".format(accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Wnioski\n",
    "Z przeprowadzonego eksperymentu wynika, że pojedynczy perceptron uczony metodą bezgradientową skutecznie klasyfikuje punkty należące do dwóch różnych klas, pod warunkiem że są one liniowo separowalne. Proces uczenia zapewnia korektę wag do momentu osiągnięcia idealnej klasyfikacji zbioru uczącego.\n",
    "\n",
    "Jednak metoda ta ma swoje ograniczenia – nie sprawdzi się w przypadku zbiorów, które nie są liniowo separowalne. Dodatkowo, szybkość uczenia może zależeć od wartości początkowych wag i współczynnika uczenia.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (psio)",
   "language": "python",
   "name": "psio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
