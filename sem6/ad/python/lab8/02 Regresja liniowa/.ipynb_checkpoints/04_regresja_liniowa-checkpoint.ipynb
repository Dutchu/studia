{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresja liniowa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regresja to proces nadzorowanego uczenia maszynowego, podobny do klasyfikacji, jednak polegający na prognozowaniu ciągłych wartości, a nie etykiet.\n",
    "Jeżeli celem analizy jest prognozowanie liczb, należy stosować regresję.\n",
    "\n",
    "Jak się okazuje, wiele modeli klasyfikacyjnych udostępnianych przez bibliotekę sklearn można wykorzystywać do rozwiązywania problemów regresyjnych. Udostępniany jest ten sam interfejs API składający się z metod fit, score i predict. Tak samo jest w przypadku wzmacniających bibliotek nowej generacji XGBoost i LightGBM.\n",
    "\n",
    "Jakość modeli regresyjnych, pomimo ich podobieństw do modeli klasyfikacyjnych i hiperparametrów, ocenia się z użyciem innych wskaźników."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regresyjny model odniesienia stanowi bazę, z którą porównywane są inne modele. Domyślnym wynikiem metody score z biblioteki sklearn jest współczynnik determinacji (oznaczany jako r2 lub R2). Jest to stopień, w jakim zmienność danych wejściowych przekłada się na zmienność prognozowanych wyników. Zazwyczaj współczynnik ten przyjmuje wartości z przedziału od 0 do 1, choć w przypadku szczególnie złych modeli może być liczbą ujemną."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W przykładach wykorzystane są dane demograficzne rejonu miasta Boston w Stanach Zjednoczonych.\n",
    "\n",
    "Poniżej znajduje się opis cech wykorzystywanego zbioru danych:\n",
    "* CRIM - Liczba przestępstw w przeliczeniu na mieszkańca miasta.\n",
    "* ZN - Odsetek gruntów mieszkalnych podzielonych na strefy o powierzchni powyżej 25 000 stóp kwadratowych.\n",
    "* INDUS - Odsetek niedetalicznych akrów biznesowych w miastach.\n",
    "* CHAS - Zmienna pomocnicza równa 1, jeżeli trakt graniczy z rzeką Charles River, lub 0 w przeciwnym razie.\n",
    "* NOX - Stężenie tlenku azotu (liczba cząsteczek na 10 milionów).\n",
    "* RM - Średnia liczba pokoi w mieszkaniu.\n",
    "* AGE - Odsetek zajmowanych przez właścicieli jednostek mieszkalnych zbudowanych przed 1940 r.\n",
    "* DIS - Średnia ważona odległości do pięciu centrów zatrudnienia w Bostonie.\n",
    "* RAD - Indeks dostępu do autostrad radialnych.\n",
    "* TAX - Pełna stawka podatku od nieruchomości per 10 000 dol.\n",
    "* PTRATIO - Stosunek liczby uczniów do nauczycieli w miastach.\n",
    "* B - Wartość $1000 · (Bk - 0,63)^2$, gdzie Bk to odsetek czarnoskórych mieszkańców miast (dane z 1978 r.).\n",
    "* LSTAT - Odsetek ludności o niższym statusie.\n",
    "* MEDV - Mediana wartości domów zajmowanych przez właścicieli przyrostowo co 1000 dol.\n",
    "\n",
    "Poniższy kod ładuje dane, dzieli je na części treningową i testową oraz tworzy osobną wersję danych zawierających znormalizowane wartości."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'medv'\n",
    "feature_names = ['crim','zn','indus','chas','nox','rm','age','dis','rad','tax','ptratio','b','lstat','medv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('.\\Data\\Boston_housing.csv',sep=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import (\n",
    "    model_selection,\n",
    "    preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_X = pd.DataFrame(df, columns=feature_names)\n",
    "bos_y = target\n",
    "\n",
    "bos_X_train, bos_X_test, bos_y_train, bos_y_test = model_selection.train_test_split(\n",
    "    bos_X,\n",
    "    bos_y,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    ")\n",
    "bos_sX = preprocessing.StandardScaler().fit_transform(\n",
    "    bos_X\n",
    ")\n",
    "bos_sX_train, bos_sX_test, bos_sy_train, bos_sy_test = model_selection.train_test_split(\n",
    "    bos_sX,\n",
    "    bos_y,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Domyślną strategią klasy DummyRegressor jest prognozowanie średniej wartości danych treningowych. Jak widać, skuteczność takiego modelu nie jest zadowalająca:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "dr = DummyRegressor()\n",
    "dr.fit(bos_X_train, bos_y_train)\n",
    "dr.score(bos_X_test, bos_y_test)\n",
    "-0.03469753992352409"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "T5xUlwcVlYg4",
    "outputId": "a8a5b188-ac9d-4a28-8e3d-91e2b120672f"
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O0beFDfiWD97"
   },
   "source": [
    "### <a name='a1'></a> Regresja Liniowa - wprowadzenie\n",
    "\n",
    "Zdefiniujmy:\n",
    "- $X_1, X_2, ..., X_n$ - zmienne niezależne (nasze dane do modelu)\n",
    "- $Y$ - zmienna docelowa\n",
    "- $y_{true}$ - wartość rzeczywista\n",
    "- $y_{pred}$ - wartość przewidziana przez model\n",
    "- $w_0, w_1,...,w_n$ - wagi do modelu (podlegaja uczeniu)\n",
    "\n",
    "W tym modelu zakłada się. ze wartość przewidywana $y_{pred}$ może być liniową kombinacją zmiennych niezależnych. Ogólna postac modelu:\n",
    "\n",
    ">  $$y_{pred}(W, X) = w_0 + w_1X_1 + ... + w_nX_n$$\n",
    ">  $$Y = XW$$\n",
    "\n",
    "gdzie:\n",
    ">  $X = \\begin{pmatrix} 1 & X_1 & X_2 & \\dots & X_n\\end{pmatrix}$,  $W = \\begin{pmatrix} w_{0} \\\\  w_{1}  \\\\ \\dots \\\\ w_{n}\\end{pmatrix}$\n",
    "\n",
    "Wprowadźmy oznaczenia:\n",
    "- $w = (w_1,...w_n)$ jako `coef_`\n",
    "- $w_0$ jako `intercept_`\n",
    "\n",
    "Regresja Liniowa polega na takim dopasowaniu wag $w_0, w_1,...,w_n$ by zminimalizować funkcję kosztu(cost function):\n",
    ">$$||XW-Y||_{2}^{2} \\rightarrow min$$  \n",
    "\n",
    "Przykład w $R^2$:  \n",
    "$Y=w_0 + w_1X_1$\n",
    "\n",
    "Przykład w $R^3$:  \n",
    "$Y=w_0 + w_1X_1 + w_2X_2$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g9TFJqBl6zsj"
   },
   "source": [
    "### Podstawowe założenia regresji liniowej\n",
    "\n",
    "* mamy zależność liniową\n",
    "* wariancja reszt jest taka sama dla wszystkich obserwacji\n",
    "* brak współliniowości (żaden z predyktorów nie stanowi kombinacji liniowej innych predyktorów)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "peQ6zK3Vf6bL"
   },
   "source": [
    "### <a name='a2'></a> Wygenerowanie danych\n",
    "\n",
    "Przykład w $R^2$:  \n",
    "$Y=w_0 + w_1X_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "hkcj5Yb_VhrK",
    "outputId": "6961388f-04ad-4930-c673-10c29a3f4a7f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(10)\n",
    "\n",
    "X = np.arange(0, 50, 0.5)\n",
    "noise = 10 * np.random.randn(100)\n",
    "y = 2 * X + 100 + noise\n",
    "X = X.reshape(-1, 1)\n",
    "\n",
    "print('Rozmiar X:',X.shape)\n",
    "print('Rozmiar y:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mFgAtdiUknXb"
   },
   "source": [
    "### <a name='a3'></a> Podział danych na zbiór treningowy i testowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "dOEYo3hCkq_z",
    "outputId": "fc56459f-c960-431c-c634-2f7143781949"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_train_shape', y_train.shape)\n",
    "print('y_test shape', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oopABUY3f93i"
   },
   "source": [
    "### <a name='a4'></a> Wizualizacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "colab_type": "code",
    "id": "c74espDVe-Wj",
    "outputId": "44a15d52-49c9-41a2-cacd-106ce822dce0"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.scatter(X_train, y_train, c='b', label='Zbiór treningowy')\n",
    "plt.scatter(X_test, y_test, c='g', label='Zbiór testowy')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sNdzJ6cRpu6T"
   },
   "source": [
    "### <a name='a5'></a> Regresja liniowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "CxMuN3E4fTWJ",
    "outputId": "c400edf1-a99c-436b-caa6-14c2daa4cbba"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "print(lin_reg.coef_)\n",
    "print(lin_reg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aFC7wSpmmbT1"
   },
   "source": [
    "Rozwiązaniem jest prosta o postaci:\n",
    "$Y=101.86 + 1.93\\cdot X_1$   \n",
    "### <a name='a6'></a>  Wizualizacja zbioru treningowego i dopasowanego modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "colab_type": "code",
    "id": "Lsaj34safVTY",
    "outputId": "21cf81e1-3f92-442a-b3fb-2c5ef12a4299"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "plt.title('Regresja Liniowa - jedna zmienna')\n",
    "plt.scatter(X_train, y_train, c='b', label='Zbiór treningowy')\n",
    "plt.plot(X, lin_reg.intercept_ + lin_reg.coef_[0] * X, c='red')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EpmSbc4Xm92m"
   },
   "source": [
    "### <a name='a7'></a>  Wizualizacja zbioru testowego i dopasowanego modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "colab_type": "code",
    "id": "N00QTIDtnFCV",
    "outputId": "a0e4e415-0483-4d13-ffb9-be96b56e9c3f"
   },
   "outputs": [],
   "source": [
    "y_pred = lin_reg.predict(X_test)\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.title('Regresja Liniowa - jedna zmienna')\n",
    "plt.scatter(X_test, y_test, c='g', label='Zbiór testowy')\n",
    "plt.plot(X, lin_reg.intercept_ + lin_reg.coef_[0] * X, c='red')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xVT9rxbRj8za"
   },
   "source": [
    "### <a name='a8'></a> Ocena modelu\n",
    "Metoda `score()` zwraca współczynnik determinacji $R^2$  naszej predykcji.\n",
    "\n",
    "Współczynnik determinacji jest zdefiniowany jako:\n",
    "\n",
    "### $R^{2} =1 - \\frac{\\sum_{t=1}^{n}(y_{pred, t} - \\bar{y}_{true} )^2}{\\sum_{t=1}^{n}(y_{true, t} - \\bar{y}_{true} )^2}$\n",
    "\n",
    "Współczynnik determinacji jest miarą stopnia dopasowania modelu do próby. Dopasowanie modelu jest tym lepsze im wartość $R^2$ jest bliżej 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Bhxx8bLgj_0S",
    "outputId": "a4c821c6-6e06-40e9-c9f2-7d9a471cc819"
   },
   "outputs": [],
   "source": [
    "lin_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IQvG16titmEF"
   },
   "outputs": [],
   "source": [
    "lin_reg.score?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d0uNxKGUjQlv"
   },
   "source": [
    "### <a name='a9'></a> Przykład złego zastosowania regresji liniowej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "colab_type": "code",
    "id": "ooqDZvsXiGkq",
    "outputId": "5e5e05cc-5b62-43a0-bc71-d1896695aeb9"
   },
   "outputs": [],
   "source": [
    "X = np.arange(-5, 5, 0.5)\n",
    "noise = 10 * np.random.randn(20)\n",
    "y = 2 * (X ** 2) + 4 + noise\n",
    "X = X.reshape(-1, 1)\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X, y)\n",
    "\n",
    "print(lin_reg.coef_)\n",
    "print(lin_reg.intercept_)\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.title('Regresja Liniowa - jedna zmienna')\n",
    "plt.plot(X, lin_reg.intercept_ + lin_reg.coef_[0] * X, c='red')\n",
    "plt.scatter(X, y)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OGb55kFe6MhN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "04_regresja_liniowa.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
